{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 第一部分",
   "id": "c216d8cee0365df1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T00:45:16.942969Z",
     "start_time": "2025-09-02T00:45:16.937470Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "57a44240eaa13d03",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 简答题",
   "id": "c63b52b914e7bb74"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1. 为什么激活函数是训练一个多层感知机（MLP）的关键要素\n",
    "2. 列举三种常用的激活函数，说明一下它们的大概形状\n",
    "sigmoid激活，乙状函数，趋近于负无穷函数趋近于0，趋近于正无穷函数趋近于1，单调递增\n",
    "tanh，近似于sigmoid，趋近于负无穷时函数趋近于-1，趋近于正无穷函数趋近于1，单调递增\n",
    "relu激活，在z小于0时是0，在z大于0时是z\n",
    "3. 反向传播的算法解决什么问题，如何工作的\n",
    "反向传播解决梯队下降问题，正向传播过程通过层层递进无法得到y_pred也就无法得到每一层的梯度，但是可以记录每层梯度计算时的A( $A_{(i)} = wZ_{(i-1)} + b$ ）,与Z（$Z_{i}=sigmoid(A_{(i)})$）,再根据链式法则从输出层反向一层层的计算梯度\n",
    "4. 列出可以在基本MLP（不考虑其他神经网络架构）中进行调整的所有超参数？如果MLP过拟合训练数据，如何调整这些超参数来解决该问题？\n",
    "隐藏层的层高，隐藏层的神经元个数，隐藏层的激活函数，使用什么优化器，优化器的学习率，训练的轮次epochs，每批次传入的样本数batch_size，权重初始化         减少层高，减少隐藏层神经元数量，选择简单的激活函数\n",
    "5. 假设有一个MLP，该MLP由一个输入层和10个直通神经元组成，随后是一个包含50个神经元的隐藏层，最后是3个神经元组成的输出层。所有人工神经元都使用ReLU激活函数。\n",
    "\n",
    "   a. 输入矩阵X的形状是什么\n",
    "    样本数 * 10\n",
    "   b. 隐藏层的权重W_hidden及其偏置b_hidden的形状分别是什么\n",
    "    10*50   50，\n",
    "   c. 输出层的权重W_output及其偏置b_output的形状是什么\n",
    "    50，3       3，\n",
    "   d. 网络输出矩阵Y的形状是什么\n",
    "    样本数 ，3\n",
    "   e. 写出输出矩阵Y的计算公式，满足Y是W_hidden, b_hidden, W_output, b_output的函数\n",
    "    RELU(RELU(X@W_hidden+b_hidden)@W_output + b_output)\n",
    "6. 如果要将电子邮件分类为垃圾邮件或正常邮件，需要在输出层中有多少个神经元？应该在输出层中使用什么激活函数？相反，如果想解决MNIST图片分类问题，则在输出层中需要有多少个神经元，应该使用哪种激活函数？如何使神经网络预测 回归话题里提到的房价？\n",
    "1个，sigmoid激活，10个softmax激活，最后输出层不加激活函数即可"
   ],
   "id": "efbfab39dff1fdac"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 编程题",
   "id": "3a345ebdc81ebc04"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "在MNIST数据集上训练深度MLP（可以使用tf.keras.datasets.mnist.load_data()加载它）。看看是否可以通过手动调整超参数获得98%以上的精度。\n",
    "\n",
    "首先尝试使用课堂上介绍的方法搜索最佳学习率（即通过以指数方式增加学习率，根据学习率变化绘制训练损失，并找到损失激增的点）。\n",
    "\n",
    "接下来，尝试使用Keras Tuner调整超参数——保存检查点，使用早停，并使用TensorBoard绘制学习曲线。"
   ],
   "id": "8ae50ffff27ba189"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T00:45:20.869411Z",
     "start_time": "2025-09-02T00:45:16.997540Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "data = tf.keras.datasets.mnist.load_data()\n",
    "# data\n",
    "\n",
    "for i in data:\n",
    "    print(i[0].shape)\n",
    "    print(i[1].shape)"
   ],
   "id": "48a63860ed875131",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T00:45:22.214352Z",
     "start_time": "2025-09-02T00:45:21.741296Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(data[0][0][0],cmap='gray')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ],
   "id": "dd2feacad9709627",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T00:45:22.414539Z",
     "start_time": "2025-09-02T00:45:22.245506Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train_all,y_train_all = data[0]\n",
    "X_test, y_test =data[1]\n",
    "X_train_all = X_train_all/255\n",
    "X_test = X_test/255"
   ],
   "id": "f687c349fd3b61c7",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T00:45:22.427591Z",
     "start_time": "2025-09-02T00:45:22.423787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train,X_valid = X_train_all[:55000,:,:],X_train_all[55000:,:,:]\n",
    "y_train,y_valid = y_train_all[:55000],y_train_all[55000:]"
   ],
   "id": "fe49bc8e013514d2",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T00:45:22.445955Z",
     "start_time": "2025-09-02T00:45:22.437758Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "# import copy\n",
    "class mycallback_for_learningrate(tf.keras.callbacks.Callback):\n",
    "    def __init__(self,n_iter= 500,start_learning_rate=1e-5,end_learning_rate=10,**kwargs):\n",
    "\n",
    "        super().__init__(**kwargs)\n",
    "        self.n_iter = n_iter\n",
    "        self.start_learning_rate = start_learning_rate\n",
    "        self.end_learning_rate = end_learning_rate\n",
    "        self.learning_rate_logs = []\n",
    "        self.losses = []\n",
    "        self.best_val_loss = np.inf\n",
    "        self.best_learning_rate = np.inf\n",
    "\n",
    "        self.upper_rate = (end_learning_rate / start_learning_rate) **(1 / n_iter)\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        # 初始化学习率\n",
    "        tf.keras.backend.set_value(self.model.optimizer.learning_rate, self.start_learning_rate)\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        # 在迭代轮次之内更新\n",
    "        if batch <=  self.n_iter:\n",
    "            currernt_lr = tf.keras.backend.get_value(self.model.optimizer.learning_rate)\n",
    "            self.learning_rate_logs.append(currernt_lr)\n",
    "            currernt_loss = logs[\"loss\"]\n",
    "            if currernt_loss < self.best_val_loss:\n",
    "                self.best_val_loss = currernt_loss\n",
    "                self.best_learning_rate = currernt_lr\n",
    "                # print(self.best_learning_rate)\n",
    "            self.losses.append(currernt_loss)\n",
    "            currernt_lr *= self.upper_rate\n",
    "            tf.keras.backend.set_value(self.model.optimizer.learning_rate, currernt_lr)\n",
    "        # 当超过迭代轮次后停止训练\n",
    "        else:\n",
    "            self.model.stop_training = True\n",
    "\n",
    "    # 停止训练时绘图，横坐标learningrate，纵坐标损失值\n",
    "    def on_train_end(self, logs=None):\n",
    "        self.plot_loss_lr()\n",
    "\n",
    "    def plot_loss_lr(self):\n",
    "        # plt.plot(self.learning_rate_logs,self.losses,\"b-\",label=\"loss\")\n",
    "        # 学习率等比用log可以等间距\n",
    "        plt.plot(np.log(self.learning_rate_logs),self.losses,\"b-\",label=\"loss\")\n",
    "        plt.xlabel(\"learning rate\")\n",
    "        plt.ylabel(\"loss\")\n",
    "        plt.show()\n",
    "\n"
   ],
   "id": "96cddc6f601cf3b6",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T00:45:22.614637Z",
     "start_time": "2025-09-02T00:45:22.461090Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 定义简单的神经网络，并启用自己的回调函数\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28,28)),\n",
    "    tf.keras.layers.Dense(300,activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(10,activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=tf.keras.optimizers.SGD(learning_rate=1e-5),metrics='sparse_categorical_accuracy')\n"
   ],
   "id": "7b32eca9ecb43f97",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T00:45:24.942219Z",
     "start_time": "2025-09-02T00:45:22.623063Z"
    }
   },
   "cell_type": "code",
   "source": [
    "my_callback = mycallback_for_learningrate()\n",
    "model.fit(X_train,y_train,epochs=1,validation_data=(X_valid,y_valid),callbacks=[my_callback],verbose=0)"
   ],
   "id": "78db35f82a6d248",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x25a44e02ad0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T00:45:24.990781Z",
     "start_time": "2025-09-02T00:45:24.985903Z"
    }
   },
   "cell_type": "code",
   "source": "my_callback.best_learning_rate",
   "id": "ae908dc3a5fa29ae",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4454405"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T00:45:25.013954Z",
     "start_time": "2025-09-02T00:45:25.008858Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "26cf8ed4bf51957b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T00:45:25.989371Z",
     "start_time": "2025-09-02T00:45:25.027616Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import keras_tuner as kt\n",
    "class myclassificationhypermodel(kt.HyperModel):\n",
    "    def build(self,hp):\n",
    "        # 参数设置：隐藏层个数、隐藏层神经元个数、激活函数、优化器\n",
    "        # tf.keras.metrics\n",
    "        n_hidden = hp.Int(\"n_hidden\", min_value=1,max_value=8, default=3)\n",
    "        n_neurons = hp.Int(\"n_neurons\", min_value=2**3,max_value=2**8, default=2**5)\n",
    "        activation = hp.Choice(\"activation\", [\"relu\",\"tanh\",\"sigmoid\",\"softplus\"])\n",
    "        optimizer = hp.Choice(\"optimizer\", [\"sgd\",\"adam\"])\n",
    "        learning_rate = hp.Float(\"learning_rate\", min_value=1e-4, max_value=1, sampling=\"log\")\n",
    "        if optimizer == \"sgd\":\n",
    "            optimizer_ = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "        else:\n",
    "            optimizer_ = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "\n",
    "        # 构建模型\n",
    "        model = tf.keras.Sequential([])\n",
    "        model.add(tf.keras.layers.Flatten(input_shape=(28,28)))\n",
    "        for _ in range(n_hidden):\n",
    "            model.add(tf.keras.layers.Dense(n_neurons,activation=activation))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(10,activation=\"softmax\"))\n",
    "\n",
    "        model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=optimizer_,metrics=['accuracy'])\n",
    "        return  model\n",
    "\n",
    "    def fit(self, hp, model,X,y,*args, **kwargs):\n",
    "        batch_size = hp.Choice(\"batch_size\", [2**4,2**5,2**6,2**7,2**8,2**9],default=32)\n",
    "        return model.fit(X, y,batch_size=batch_size, **kwargs)"
   ],
   "id": "76ea49a84c170f50",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "kt_random_search = kt.RandomSearch(myclassificationhypermodel(), objective=\"val_accuracy\", max_trials=5, overwrite=True, directory=\"./models/mnist_logs\", project_name=\"my_rnd_search\", seed=42)\n",
    "#\n",
    "# early_stop_cb = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, mode=\"min\", restore_best_weights=True)\n",
    "\n",
    "kt_random_search.search(X_train, y_train, epochs = 10, validation_data=(X_valid, y_valid))"
   ],
   "id": "e256fd82f0b2aa7e",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 05s]\n",
      "val_accuracy: 0.9368000030517578\n",
      "\n",
      "Best val_accuracy So Far: 0.980400025844574\n",
      "Total elapsed time: 00h 01m 14s\n"
     ]
    }
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T00:46:40.210804Z",
     "start_time": "2025-09-02T00:46:40.207345Z"
    }
   },
   "cell_type": "code",
   "source": "# vars(kt_random_search)",
   "id": "b11a88c3f52b8efa",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T00:46:40.233820Z",
     "start_time": "2025-09-02T00:46:40.218372Z"
    }
   },
   "cell_type": "code",
   "source": "# kt_random_search.get_best_hyperparameters(num_trials=3)[0].values",
   "id": "d510015bb77afe86",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T00:46:40.481753Z",
     "start_time": "2025-09-02T00:46:40.240796Z"
    }
   },
   "cell_type": "code",
   "source": "best_model = kt_random_search.get_best_models(num_models = 1)[0]",
   "id": "1a60f3c16900a689",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T00:46:40.493825Z",
     "start_time": "2025-09-02T00:46:40.488941Z"
    }
   },
   "cell_type": "code",
   "source": [
    "best_hp = kt_random_search.get_best_hyperparameters(num_trials=1)[0]\n",
    "# hypermodel = myclassificationhypermodel()\n",
    "# best_model = hypermodel.build(best_hp)"
   ],
   "id": "d44c31f10f4fc23d",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T00:46:40.511898Z",
     "start_time": "2025-09-02T00:46:40.505935Z"
    }
   },
   "cell_type": "code",
   "source": "best_hp.values",
   "id": "37d6106f99a45bc4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_hidden': 5,\n",
       " 'n_neurons': 235,\n",
       " 'activation': 'relu',\n",
       " 'optimizer': 'adam',\n",
       " 'learning_rate': 0.00014800038812985168,\n",
       " 'batch_size': 128}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T00:49:00.528660Z",
     "start_time": "2025-09-02T00:46:45.842397Z"
    }
   },
   "cell_type": "code",
   "source": [
    "earlystop_cb = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5,restore_best_weights=True)\n",
    "from datetime import datetime\n",
    "\n",
    "current_date = datetime.now()\n",
    "formatted_date = current_date.strftime(\"%Y_%m_%d\")\n",
    "dir_path = \"./models/mnist_logs/tensorboard\"\n",
    "\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=dir_path+\"/\"+formatted_date,)\n",
    "\n",
    "best_model.fit(X_train_all,y_train_all,epochs=100,validation_data=(X_valid,y_valid),callbacks=[earlystop_cb,tensorboard])"
   ],
   "id": "dd934c08fa269e76",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0686 - accuracy: 0.9779 - val_loss: 0.0639 - val_accuracy: 0.9804\n",
      "Epoch 2/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0449 - accuracy: 0.9857 - val_loss: 0.0372 - val_accuracy: 0.9890\n",
      "Epoch 3/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0342 - accuracy: 0.9888 - val_loss: 0.0284 - val_accuracy: 0.9910\n",
      "Epoch 4/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0297 - accuracy: 0.9904 - val_loss: 0.0228 - val_accuracy: 0.9938\n",
      "Epoch 5/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0233 - accuracy: 0.9921 - val_loss: 0.0198 - val_accuracy: 0.9930\n",
      "Epoch 6/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0202 - accuracy: 0.9934 - val_loss: 0.0172 - val_accuracy: 0.9946\n",
      "Epoch 7/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0174 - accuracy: 0.9942 - val_loss: 0.0099 - val_accuracy: 0.9974\n",
      "Epoch 8/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0156 - accuracy: 0.9949 - val_loss: 0.0087 - val_accuracy: 0.9978\n",
      "Epoch 9/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0129 - accuracy: 0.9959 - val_loss: 0.0073 - val_accuracy: 0.9980\n",
      "Epoch 10/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0129 - accuracy: 0.9957 - val_loss: 0.0111 - val_accuracy: 0.9964\n",
      "Epoch 11/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0111 - accuracy: 0.9962 - val_loss: 0.0340 - val_accuracy: 0.9898\n",
      "Epoch 12/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0120 - accuracy: 0.9959 - val_loss: 0.0046 - val_accuracy: 0.9986\n",
      "Epoch 13/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0101 - accuracy: 0.9965 - val_loss: 0.0080 - val_accuracy: 0.9974\n",
      "Epoch 14/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0081 - accuracy: 0.9974 - val_loss: 0.0120 - val_accuracy: 0.9956\n",
      "Epoch 15/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0102 - accuracy: 0.9967 - val_loss: 0.0086 - val_accuracy: 0.9980\n",
      "Epoch 16/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 0.0067 - val_accuracy: 0.9978\n",
      "Epoch 17/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.0024 - val_accuracy: 0.9992\n",
      "Epoch 18/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0078 - accuracy: 0.9975 - val_loss: 0.0058 - val_accuracy: 0.9980\n",
      "Epoch 19/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0064 - accuracy: 0.9978 - val_loss: 0.0047 - val_accuracy: 0.9984\n",
      "Epoch 20/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 0.0031 - val_accuracy: 0.9990\n",
      "Epoch 21/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.0070 - val_accuracy: 0.9970\n",
      "Epoch 22/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.0029 - val_accuracy: 0.9990\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x25a487c7790>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T00:49:11.018257Z",
     "start_time": "2025-09-02T00:49:10.323690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(np.argmax(best_model.predict(X_test),axis=1),y_test)"
   ],
   "id": "bd8d87088cf5632f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9822"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# tensorboard --logdir=.\\models\\mnist_logs\\tensorboard\\2025_09_02",
   "id": "92b9188ef6055638"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 第二部分",
   "id": "36820ad9e15ee6a4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "第二部分要求构建一个基本的softmax回归算法，以及一个简单的两层神经网络。将使用原生Python（使用numpy库），不借助keras实现这些算法\n",
    "\n",
    "在此过程中，将提供一些关于如何实现这些不同函数的指导，但总体而言，细节需要自己实现。 应该尽量使用 numpy 中的线性代数调用：for/while循环通常会使代码运行速度比预期慢得多。\n",
    "\n",
    "**请仔细阅读作业说明!!!**"
   ],
   "id": "ef8ee36ab3194bee"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "去命令行（cmd/Anaconda Powershell Prompt /其他终端）运行如下指令（激活开发环境一定要最先执行），安装这部分作业依赖的python库：\n",
    "- 激活开发环境：conda activate homl3\n",
    "- 安装numdifftools：conda install numdifftools\n",
    "- 安装pytest：conda install pytest\n"
   ],
   "id": "8f03383cd433925f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 第一题：简单的加法函数，以及使用pytest测试代码",
   "id": "4c466d5685d4d03c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "为了说明这部分作业的代码+数据，以及pytest使用，将使用一个实现 add函数 的简单示例。\n",
    "\n",
    "```\n",
    "data/\n",
    "    train-images-idx3-ubyte.gz\n",
    "    train-labels-idx1-ubyte.gz\n",
    "    t10k-images-idx3-ubyte.gz\n",
    "    t10k-labels-idx1-ubyte.gz\n",
    "src/\n",
    "    simple_ml.py\n",
    "tests/\n",
    "    test_simple_ml.py\n",
    "```\n",
    "\n",
    "data/ 目录包含这部分作业所需的数据（MNIST 数据集的副本）；src/ 目录包含实现功能所需的源代码；tests/ 目录包含用于测试实现代码是否正确的代码\n",
    "\n",
    "第一题要求实现 src/目录里 simple_ml.py内的 add函数（这个简单的函数实际上并没有用到，它只是一个帮助熟悉作业结构的示例）。查看 src/simple_ml.py 文件，将找到 add() 函数的定义"
   ],
   "id": "ec65b18ce87572e0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 测试代码",
   "id": "6cd5d2fcdd8098e7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "现在需要测试一下你的代码是否能正确运行，正确运行才说明实现没问题。\n",
    "\n",
    "在这部分作业中，将使用pytest对代码进行单元测试。在 src/simple_ml.py 文件中 写完 add函数的实现后，去命令行里确保已经激活了homl3环境（conda activate homl3）， 确保homl3环境里安装过了numdifftools和pytest，确定命令行里显示的文件路径在 作业8的目录（这个目录同时有data/, src/和tests/文件夹），然后执行以下命令：\n",
    "\n",
    "python -m pytest -k \"add\"\n",
    "\n",
    "如果一切正常，你会看到类似这样的图片：\n",
    "![测试add通过](../images/homework/neural_network/p1.png)\n",
    "\n",
    "想看测试如何进行的，可以去查看tests/test_simple_ml.py文件，python -m pytest -k \"add\"指令刚刚运行的是 文件里的test_add() 函数\n",
    "\n",
    "如果错误地实现了某些内容（例如，将上面的 x + y 更改为 x - y），那么测试将会失败，并且 pytest 将会指示相应的测试失败。\n",
    "\n",
    "比如把x+y，换成x-y后，执行python -m pytest -k \"add\"：\n",
    "![测试add不通过](../images/homework/neural_network/p2.png)"
   ],
   "id": "d50035ed39acb088"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "b如图所见，将收到一个错误，指示断言失败，然后就可以使用它来返回并调整实现代码。应该能够熟练地阅读和跟踪测试文件，以便更好地理解正确的实现应该如何工作\n",
    "\n",
    "学习正确开发和使用单元测试对于现代软件开发至关重要，希望这次作业帮助了解单元测试在软件开发中的典型用法。\n",
    "\n",
    "当然，这次作业不一定需要编写自己的测试去确保自己实现正确，但应该熟悉如何阅读提供的测试文件，以便了解要实现的函数应该如何运行。但是，也绝对鼓励为自己的实现编写额外的测试。\n",
    "\n",
    "如果习惯通过打印语句调试代码，请注意，pytest 默认会捕获任何输出（隐藏掉测试代码执行的print）。可以通过将 -s 传递给 pytest 来禁用此行为并让测试在所有情况下显示所有输出。"
   ],
   "id": "2efc3a6f7149b279"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 第二题：用gzip和struct处理压缩文件和二进制数据，加载MNIST数据",
   "id": "d52dd69c5a4d201b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "现在已经熟悉了测试工具pytest，接下来在 src/simple_ml.py 中需要实现的函数上尝试一下：parse_mnist_data() 函数。\n",
    "\n",
    "这个函数也有文档字符串（docstring），请仔细阅读它们。\n",
    "\n",
    "然后，请访问 http://yann.lecun.com/exdb/mnist/ 了解 MNIST 数据的二进制格式。然后编写函数读取此类文件，并根据文档字符串中的规范返回 numpy 数组）。建议使用 Python 中的 struct 模块（以及 gzip 模块，当然还有 numpy 本身）来实现此函数。\n",
    "\n",
    "当然可以利用AI搜索这个部分的代码实现，但了解了MNIST数据的二进制格式和gzip，struct的简单使用后，能理解AI产出的代码为什么正确\n",
    "\n",
    "实现函数后，去命令行运行本地单元测试， 同样确保命令行激活了homl3环境，确保路径在作业8目录下（有data/,src/和tests/文件）， 后面的题不再强调\n",
    "\n",
    "python -m pytest -k \"parse_mnist\""
   ],
   "id": "68f7d3f1c9a1c4f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 第三题：Softmax损失",
   "id": "a1f0f951071f9cb1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "在 `src/simple_ml.py` 文件的 `softmax_loss()` 函数中实现 softmax（也称为交叉熵）损失。对于一个可以取值 $ y \\in \\{1, \\ldots, k\\} $ 的多类输出，softmax 损失接收一个对数几率向量 $ z \\in \\mathbb{R}^k $ 和真实类别 $ y \\in \\{1, \\ldots, k\\} $ 作为输入，并返回由以下公式定义的损失：\n",
    "\n",
    "$\\ell_{\\text{softmax}}(z, y) = \\log (\\sum_{i=1}^{k} \\exp z_i) - z_y$\n",
    "\n",
    "对数几率向量z，可以看成被softmax激活之前的值，对公式有疑惑，或者对z的意义有疑惑的，可以参考softmax回归的笔记，并自己推导一下损失公式是否正确\n",
    "\n",
    "请注意，如其文档字符串（docstring）所述，`softmax_loss()` 函数接收一个二维的对数几率数组（即，一批不同样本的 $ k $ 维对数几率）加上一个对应的一维真实标签数组，并应返回整批样本的平均 softmax 损失。请注意，为了正确实现此功能，你不应使用任何循环，而是完全使用 numpy 的向量化操作进行计算（为此设定预期，实现代码可以少到一行代码）。"
   ],
   "id": "953808de07690b8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "实现完成后，可以去命令行进行单元测试：python -m pytest -k \"softmax_loss\"",
   "id": "21787c42fa9b7477"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 第四题：softmax回归小批量梯度下降",
   "id": "b7fe01a86a24019c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "在这个问题中，你将实现（线性）softmax 回归的小批量梯度下降）。考虑一个假设函数，该函数通过以下公式将 $ n $ 维输入转换为 $ k $ 维对数几率：\n",
    "\n",
    "$h(x) = \\Theta^T x$\n",
    "\n",
    "其中 $ x \\in \\mathbb{R}^n $ 是输入，$\\Theta \\in \\mathbb{R}^{n \\times k}$ 是模型参数。给定数据集 $\\{(x^{(i)} \\in \\mathbb{R}^n, y^{(i)} \\in \\{1, \\ldots, k\\})\\}$，其中 $ i = 1, \\ldots, m $，softmax 回归相关的优化问题因此由下式给出：\n",
    "\n",
    "$\\text{minimize} \\frac{1}{m} \\sum_{i=1}^{m} \\ell_{\\text{softmax}} (\\Theta^T x^{(i)}, y^{(i)})$\n",
    "\n",
    "线性 softmax 目标的梯度由下式给出，有疑惑的可以结合softmax回归的笔记验证\n",
    "\n",
    "$\\nabla_\\Theta \\ell_{\\text{softmax}} (\\Theta^T x, y) = x(z - e_y)^T$\n",
    "\n",
    "其中\n",
    "\n",
    "$z = \\frac{\\exp(\\Theta^T x)}{1^T \\exp(\\Theta^T x)} = \\text{normalize}(\\exp(\\Theta^T x))$\n",
    "\n",
    "（即 $ z $ 只是归一化的 softmax 概率），并且 $ e_y $ 表示 y 分类的独热编码，即一个所有元素为零，只有第 $ y $ 个位置为 1 的向量。\n",
    "\n",
    "也可以用更紧凑的符号来表示，方便代码实现，即，如果让 $ X \\in \\mathbb{R}^{m \\times n} $ 表示某个 $ m $ 个输入的特征矩阵（整个数据集或一个小批量），$ y \\in \\{1, \\ldots, k\\}^m $ 是对应的标签向量，并且 $ \\ell_{\\text{softmax}} $ 表示平均 softmax 损失，那么\n",
    "\n",
    "$\\nabla_\\Theta \\ell_{\\text{softmax}}(X \\Theta, y) = \\frac{1}{m} X^T (Z - I_y)$\n",
    "\n",
    "其中\n",
    "\n",
    "$Z = \\text{normalize}(\\exp(X \\Theta)) \\quad (\\text{归一化按行应用})$\n",
    "\n",
    "表示对数几率矩阵，而 $ I_y \\in \\mathbb{R}^{m \\times k} $ 表示 $ y $ 中标签的 逐个转成 独热编码，按行连接\n",
    "\n",
    "使用这些梯度，实现 `softmax_regression_epoch()` 函数，该函数使用指定的学习率/步长 $ \\eta $ 和小批量大小 `batch_size` 运行单个轮次（对数据集的一次遍历）。如其文档字符串所述，你的函数应该就地修改 Theta 数组。实现后，请去命令行运行测试。\n",
    "\n",
    "python -m pytest -k \"softmax_regression_epoch\""
   ],
   "id": "22b73c8ad436404b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 用softmax回归训练MNIST",
   "id": "691a02c8be918f7b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "虽然这不包含在测试中，但既然你已经编写了这段代码，你也可以尝试使用 SGD 训练一个完整的 MNIST 线性分类器。为此，你可以使用 src/simple_nn.py 文件中的 train_softmax() 函数（已经编写好了这个函数，所以无需自行编写，但可以查看一下它的功能）。\n",
    "\n",
    "可以使用以下代码了解它的工作原理。作为参考，如下所示，我的实现在 notebook 上运行时间约为 2 秒，测试集错误率为 7.97%。"
   ],
   "id": "c3708dee1e435722"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T00:58:10.283028Z",
     "start_time": "2025-09-02T00:58:10.272766Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "sys.path.append(\"src/\")"
   ],
   "id": "1bbe1cf21928288b",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T00:58:15.033884Z",
     "start_time": "2025-09-02T00:58:11.552735Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from simple_nn import train_softmax, parse_mnist\n",
    "\n",
    "X_tr, y_tr = parse_mnist(\"data/train-images-idx3-ubyte.gz\",\n",
    "                         \"data/train-labels-idx1-ubyte.gz\")\n",
    "X_te, y_te = parse_mnist(\"data/t10k-images-idx3-ubyte.gz\",\n",
    "                         \"data/t10k-labels-idx1-ubyte.gz\")\n",
    "\n",
    "train_softmax(X_tr, y_tr, X_te, y_te, epochs=10, lr=0.2, batch=100)"
   ],
   "id": "72a9aa980f34a079",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch | Train Loss | Train Err | Test Loss | Test Err |\n",
      "|     0 |    0.35134 |   0.10182 |   0.33588 |  0.09400 |\n",
      "|     1 |    0.32142 |   0.09268 |   0.31086 |  0.08730 |\n",
      "|     2 |    0.30802 |   0.08795 |   0.30097 |  0.08550 |\n",
      "|     3 |    0.29987 |   0.08532 |   0.29558 |  0.08370 |\n",
      "|     4 |    0.29415 |   0.08323 |   0.29215 |  0.08230 |\n",
      "|     5 |    0.28981 |   0.08182 |   0.28973 |  0.08090 |\n",
      "|     6 |    0.28633 |   0.08085 |   0.28793 |  0.08080 |\n",
      "|     7 |    0.28345 |   0.07997 |   0.28651 |  0.08040 |\n",
      "|     8 |    0.28100 |   0.07923 |   0.28537 |  0.08010 |\n",
      "|     9 |    0.27887 |   0.07847 |   0.28442 |  0.07970 |\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 在1个隐藏层的神经网络上进行小批量梯度下降",
   "id": "3d5e02bfcc97769d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "现在已经为线性分类器编写了SGD，现在考虑一个简单的两层神经网络的情况。具体来说，对于输入 $ x \\in \\mathbb{R}^n $，考虑一个形式如下的两层神经网络（无偏置项）：\n",
    "\n",
    "$ z = W_2^T ReLU(W_1^T x) $\n",
    "\n",
    "其中 $ W_1 \\in \\mathbb{R}^{n \\times d} $ 和 $ W_2 \\in \\mathbb{R}^{d \\times k} $ 表示网络的权重（具有 $ d $ 维隐藏单元），而 $ z \\in \\mathbb{R}^k $ 表示网络输出的对数几率。我们再次使用 softmax/交叉熵损失，这意味着我们要解决以下优化问题：\n",
    "\n",
    "$\\text{minimize } \\frac{1}{W_1, W_2} \\sum_{i=1}^m \\ell_{\\text{softmax}}(W_2^T ReLU(W_1^T x^{(i)}), y^{(i)})$\n",
    "\n",
    "或者，使用矩阵 $ X \\in \\mathbb{R}^{m \\times n} $ 来描述批量形式，这也可以写成：\n",
    "\n",
    "$\\text{minimize } \\ell_{\\text{softmax}}(ReLU(XW_1)W_2, y)$\n",
    "\n",
    "使用链式法则，可以推导出该网络的反向传播更新（为了便于实现，这里提供最终形式）。具体来说，令：\n",
    "\n",
    "$Z_1 \\in \\mathbb{R}^{m \\times d} = ReLU(XW_1)$\n",
    "\n",
    "$G_2 \\in \\mathbb{R}^{m \\times k} = \\text{normalize}(\\exp(Z_1 W_2)) - I_y$\n",
    "\n",
    "$G_1 \\in \\mathbb{R}^{m \\times d} = 1\\{Z_1 > 0\\} \\circ (G_2 W_2^T)$\n",
    "\n",
    "其中 $ 1\\{Z_1 > 0\\} $ 是一个二进制矩阵，其条目根据 $ Z_1 $ 中的每个项是否严格为正而等于零或一，而 $\\circ$ 表示逐元素乘法。那么目标的梯度由下式给出：\n",
    "\n",
    "$\\nabla_{W_1} \\ell_{\\text{softmax}}(ReLU(XW_1)W_2, y) = \\frac{1}{m} X^T G_1$\n",
    "\n",
    "$\\nabla_{W_2} \\ell_{\\text{softmax}}(ReLU(XW_1)W_2, y) = \\frac{1}{m} Z_1^T G_2$\n",
    "\n",
    "**注意：** 如果这些精确方程的细节对你来说有点神秘，不必太担心。这些只是两层ReLU网络的标准反向传播方程：$ Z_1 $ 项只是计算\"前向\"传播，而 $ G_2 $ 和 $ G_1 $ 项表示反向传播。但是更新的精确形式可能会因你使用的神经网络符号、制定损失函数的具体方式、是否之前以矩阵形式推导过这些等因素而有所不同。（毕竟，在某种程度上，深度学习系统（比如tensorflow）的整个重点是我们不需要费心进行这些手动计算）。\n"
   ],
   "id": "a95acd16726bcea5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "使用这些梯度，现在在 src/simple_nn.py 文件中编写 nn_epoch() 函数。与上一个问题一样，你的解决方案应该修改 W1 和 W2 数组。实现该函数后，运行以下测试。请务必使用上述表达式所示的矩阵运算来实现该函数：这比尝试使用循环更快、更高效（并且所需的代码也更少）。\n",
    "\n",
    "实现完成后，去命令运行单元测试：python -m pytest -k \"nn_epoch\""
   ],
   "id": "f0f777d8430f7718"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 训练神经网络",
   "id": "6aa812d9bf8c5dd1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T01:08:42.261118Z",
     "start_time": "2025-09-02T01:07:38.861623Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "sys.path.append(\"src/\")\n",
    "import importlib\n",
    "import simple_nn\n",
    "importlib.reload(simple_nn) # 重新载入simple_nn， 防止刚才的训练代码产生了缓存，影响了simple_nn\n",
    "\n",
    "\n",
    "from simple_nn import train_nn, parse_mnist\n",
    "\n",
    "X_tr, y_tr = parse_mnist(\"data/train-images-idx3-ubyte.gz\",\n",
    "                         \"data/train-labels-idx1-ubyte.gz\")\n",
    "X_te, y_te = parse_mnist(\"data/t10k-images-idx3-ubyte.gz\",\n",
    "                         \"data/t10k-labels-idx1-ubyte.gz\")\n",
    "train_nn(X_tr, y_tr, X_te, y_te, hidden_dim=400, epochs=20, lr=0.2)"
   ],
   "id": "d4b9f0be3383aff1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch | Train Loss | Train Err | Test Loss | Test Err |\n",
      "|     0 |    0.15324 |   0.04697 |   0.16305 |  0.04920 |\n",
      "|     1 |    0.09940 |   0.02985 |   0.11694 |  0.03710 |\n",
      "|     2 |    0.07419 |   0.02143 |   0.09750 |  0.03220 |\n",
      "|     3 |    0.05944 |   0.01717 |   0.08751 |  0.02890 |\n",
      "|     4 |    0.04811 |   0.01338 |   0.08089 |  0.02530 |\n",
      "|     5 |    0.03994 |   0.01068 |   0.07613 |  0.02420 |\n",
      "|     6 |    0.03447 |   0.00880 |   0.07343 |  0.02310 |\n",
      "|     7 |    0.03025 |   0.00772 |   0.07200 |  0.02260 |\n",
      "|     8 |    0.02671 |   0.00640 |   0.07074 |  0.02200 |\n",
      "|     9 |    0.02358 |   0.00555 |   0.06970 |  0.02120 |\n",
      "|    10 |    0.02120 |   0.00482 |   0.06870 |  0.02100 |\n",
      "|    11 |    0.01906 |   0.00405 |   0.06813 |  0.02050 |\n",
      "|    12 |    0.01723 |   0.00332 |   0.06748 |  0.02070 |\n",
      "|    13 |    0.01557 |   0.00288 |   0.06680 |  0.02070 |\n",
      "|    14 |    0.01419 |   0.00242 |   0.06638 |  0.02070 |\n",
      "|    15 |    0.01301 |   0.00208 |   0.06597 |  0.02070 |\n",
      "|    16 |    0.01185 |   0.00183 |   0.06567 |  0.02080 |\n",
      "|    17 |    0.01086 |   0.00158 |   0.06508 |  0.02000 |\n",
      "|    18 |    0.01003 |   0.00132 |   0.06501 |  0.01960 |\n",
      "|    19 |    0.00915 |   0.00102 |   0.06448 |  0.01950 |\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "作为参考，我的实现花了30多秒训练，最终在mnist的测试集达到了1.93%的错误率，只用了大概20多行代码",
   "id": "3f405f7bab4ae611"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "635e0efef5731506"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
